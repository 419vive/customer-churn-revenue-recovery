#!/usr/bin/env python
"""
Advanced Analysis Script
Comprehensive breakdown of customer behavior and business insights
"""

import pandas as pd
import numpy as np
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# Import our modules
from analytics.rfm_analysis import RFMAnalyzer
from analytics.cohort_analysis import CohortAnalyzer
from analytics.ltv_modeling import LTVPredictor
from analytics.advanced_analysis import AdvancedAnalyzer

def load_data():
    """Load sample data"""
    print("üìä Loading data...")
    orders = pd.read_csv('../data/sample_orders.csv')
    payments = pd.read_csv('../data/sample_payments.csv')
    customers = pd.read_csv('../data/sample_customers.csv')
    
    print(f"‚úÖ Loaded {len(orders)} orders, {len(payments)} payments, {len(customers)} customers")
    return orders, payments, customers

def run_comprehensive_analysis():
    """Run complete advanced analysis with detailed breakdowns"""
    print("üöÄ Starting Comprehensive Olist Analytics")
    print("=" * 80)
    
    # Load data
    orders, payments, customers = load_data()
    
    # === PHASE 1: BASIC ANALYSIS ===
    print("\n" + "=" * 80)
    print("üìä PHASE 1: CORE ANALYTICS")
    print("=" * 80)
    
    # RFM Analysis
    print("\nüéØ Running RFM Analysis...")
    last_order_date = pd.to_datetime(orders['order_purchase_timestamp']).max()
    reference_date = last_order_date + pd.Timedelta(days=1)
    
    rfm = RFMAnalyzer(reference_date)
    rfm_df = rfm.calculate_rfm(orders, payments)
    rfm_scores = rfm.assign_scores(rfm_df)
    rfm_segments = rfm.create_segments(rfm_scores)
    
    print("Basic RFM Summary:")
    print(rfm.get_segment_summary(rfm_segments))
    
    # Cohort Analysis
    print("\nüìÖ Running Cohort Analysis...")
    cohort = CohortAnalyzer()
    cohort_df = cohort.create_cohorts(orders, payments)
    retention = cohort.calculate_retention(cohort_df)
    
    print("Retention Matrix (first 4 months):")
    print(retention.iloc[:, :5])
    
    # LTV Analysis
    print("\nüí∞ Running LTV Analysis...")
    ltv = LTVPredictor()
    ltv_df = ltv.calculate_historical_ltv(orders, payments)
    ltv_segments = ltv.segment_ltv(ltv_df)
    
    print("LTV Summary:")
    cac_analysis = ltv.calculate_cac_payback(ltv_df)
    print(cac_analysis)
    
    # === PHASE 2: ADVANCED BREAKDOWN ===
    print("\n" + "=" * 80)
    print("üîç PHASE 2: ADVANCED BREAKDOWN ANALYSIS")
    print("=" * 80)
    
    # Initialize advanced analyzer
    advanced = AdvancedAnalyzer()
    
    # Detailed RFM breakdown
    advanced.detailed_rfm_breakdown(rfm_segments)
    
    # Deep cohort analysis
    advanced.cohort_deep_dive(cohort_df, retention)
    
    # Advanced LTV insights
    customer_journey = advanced.ltv_deep_analysis(ltv_segments, orders, payments)
    
    # Payment behavior analysis
    advanced.payment_method_analysis(payments)
    
    # === PHASE 3: STRATEGIC INSIGHTS ===
    print("\n" + "=" * 80)
    print("üéØ PHASE 3: STRATEGIC INSIGHTS & RECOMMENDATIONS")
    print("=" * 80)
    
    # Comprehensive business insights
    advanced.generate_comprehensive_insights(rfm_segments, cohort_df, ltv_segments, payments)
    
    # === PHASE 4: ADDITIONAL INSIGHTS ===
    print("\n" + "=" * 80)
    print("üìà PHASE 4: ADDITIONAL BUSINESS INSIGHTS")
    print("=" * 80)
    
    # Customer lifecycle insights
    analyze_customer_lifecycle(orders, payments, rfm_segments)
    
    # Revenue trend analysis
    analyze_revenue_trends(orders, payments)
    
    # Geographic insights (if available)
    analyze_geographic_patterns(customers, orders, payments)
    
    # === SAVE ENHANCED RESULTS ===
    print("\nüíæ Saving enhanced analysis results...")
    
    # Save all results with timestamps
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    rfm_segments.to_csv(f'../outputs/rfm_segments_detailed_{timestamp}.csv', index=False)
    retention.to_csv(f'../outputs/retention_matrix_{timestamp}.csv')
    ltv_segments.to_csv(f'../outputs/customer_ltv_detailed_{timestamp}.csv')
    customer_journey.to_csv(f'../outputs/customer_journey_{timestamp}.csv')
    
    # Generate summary report
    generate_executive_summary(rfm_segments, retention, ltv_segments, customer_journey)
    
    print(f"‚úÖ Advanced analysis complete! Results saved with timestamp {timestamp}")
    print("üìä Check outputs/ folder for detailed CSV files")
    print("üìÑ Executive summary saved as executive_summary.txt")

def analyze_customer_lifecycle(orders, payments, rfm_segments):
    """Analyze customer lifecycle patterns"""
    print("\nüîÑ CUSTOMER LIFECYCLE ANALYSIS:")
    print("-" * 60)
    
    # Merge data
    df = orders.merge(payments, on='order_id')
    df['order_date'] = pd.to_datetime(df['order_purchase_timestamp'])
    
    # Calculate days between orders for each customer
    df_sorted = df.sort_values(['customer_id', 'order_date'])
    df_sorted['days_between_orders'] = df_sorted.groupby('customer_id')['order_date'].diff().dt.days
    
    # Average time between orders
    avg_days_between = df_sorted['days_between_orders'].mean()
    median_days_between = df_sorted['days_between_orders'].median()
    
    print(f"   Average days between orders: {avg_days_between:.1f}")
    print(f"   Median days between orders: {median_days_between:.1f}")
    
    # Purchase frequency patterns
    order_frequency = df.groupby('customer_id').size()
    
    print(f"\n   Purchase Frequency Distribution:")
    for freq in [1, 2, 3, 4, 5]:
        count = (order_frequency == freq).sum()
        pct = count / len(order_frequency) * 100
        print(f"     {freq} orders: {count} customers ({pct:.1f}%)")
    
    # High-value customer journey
    high_value_customers = df.groupby('customer_id')['payment_value'].sum().nlargest(10)
    print(f"\n   Top 10 Customer Values:")
    for customer_id, value in high_value_customers.items():
        orders_count = len(df[df['customer_id'] == customer_id])
        print(f"     Customer {customer_id}: ${value:.2f} ({orders_count} orders)")

def analyze_revenue_trends(orders, payments):
    """Analyze revenue trends over time"""
    print("\nüìà REVENUE TREND ANALYSIS:")
    print("-" * 60)
    
    # Merge and prepare data
    df = orders.merge(payments, on='order_id')
    df['order_date'] = pd.to_datetime(df['order_purchase_timestamp'])
    df['month'] = df['order_date'].dt.to_period('M')
    
    # Monthly revenue trends
    monthly_revenue = df.groupby('month').agg({
        'payment_value': 'sum',
        'order_id': 'count',
        'customer_id': 'nunique'
    }).round(2)
    
    monthly_revenue.columns = ['revenue', 'orders', 'customers']
    monthly_revenue['avg_order_value'] = monthly_revenue['revenue'] / monthly_revenue['orders']
    monthly_revenue['revenue_per_customer'] = monthly_revenue['revenue'] / monthly_revenue['customers']
    
    print("   Monthly Performance Summary:")
    print(monthly_revenue.head(6))
    
    # Growth rates
    monthly_revenue['revenue_growth'] = monthly_revenue['revenue'].pct_change() * 100
    monthly_revenue['customer_growth'] = monthly_revenue['customers'].pct_change() * 100
    
    print(f"\n   Average monthly revenue growth: {monthly_revenue['revenue_growth'].mean():.1f}%")
    print(f"   Average monthly customer growth: {monthly_revenue['customer_growth'].mean():.1f}%")

def analyze_geographic_patterns(customers, orders, payments):
    """Analyze geographic distribution patterns"""
    print("\nüó∫Ô∏è  GEOGRAPHIC ANALYSIS:")
    print("-" * 60)
    
    # State distribution
    if 'customer_state' in customers.columns:
        state_dist = customers['customer_state'].value_counts().head(10)
        
        print("   Top 10 States by Customer Count:")
        for state, count in state_dist.items():
            pct = count / len(customers) * 100
            print(f"     {state}: {count} customers ({pct:.1f}%)")
        
        # Revenue by state
        customer_orders = orders.merge(customers, on='customer_id')
        revenue_by_state = customer_orders.merge(payments, on='order_id').groupby('customer_state')['payment_value'].sum().sort_values(ascending=False).head(10)
        
        print(f"\n   Top 10 States by Revenue:")
        for state, revenue in revenue_by_state.items():
            print(f"     {state}: ${revenue:.2f}")
    else:
        print("   Geographic data not available in sample dataset")

def generate_executive_summary(rfm_segments, retention, ltv_segments, customer_journey):
    """Generate executive summary report"""
    
    summary_text = f"""
EXECUTIVE SUMMARY - OLIST E-COMMERCE ANALYTICS
===============================================
Generated: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

KEY PERFORMANCE METRICS
-----------------------
‚Ä¢ Total Customers Analyzed: {len(rfm_segments):,}
‚Ä¢ Average Customer LTV: ${ltv_segments['total_revenue'].mean():.2f}
‚Ä¢ Average Orders per Customer: {customer_journey['total_orders'].mean():.2f}
‚Ä¢ Average Order Value: ${customer_journey['avg_order_value'].mean():.2f}

CUSTOMER SEGMENTATION INSIGHTS
------------------------------
‚Ä¢ Champions (High Value): {len(rfm_segments[rfm_segments['segment'] == 'Champions'])} customers ({len(rfm_segments[rfm_segments['segment'] == 'Champions'])/len(rfm_segments)*100:.1f}%)
‚Ä¢ At Risk Customers: {len(rfm_segments[rfm_segments['segment'] == 'At Risk'])} customers ({len(rfm_segments[rfm_segments['segment'] == 'At Risk'])/len(rfm_segments)*100:.1f}%)
‚Ä¢ Lost Customers: {len(rfm_segments[rfm_segments['segment'] == 'Lost'])} customers ({len(rfm_segments[rfm_segments['segment'] == 'Lost'])/len(rfm_segments)*100:.1f}%)

RETENTION PERFORMANCE
--------------------
‚Ä¢ Month 1 Retention: {retention.iloc[:, 1].mean():.1f}% (Industry benchmark: 20-30%)
‚Ä¢ Month 2 Retention: {retention.iloc[:, 2].mean():.1f}%
‚Ä¢ Month 3 Retention: {retention.iloc[:, 3].mean():.1f}%

REVENUE OPPORTUNITIES
--------------------
‚Ä¢ Champions Revenue Share: {rfm_segments[rfm_segments['segment'] == 'Champions']['monetary'].sum()/rfm_segments['monetary'].sum()*100:.1f}%
‚Ä¢ At Risk Customer Value: ${rfm_segments[rfm_segments['segment'] == 'At Risk']['monetary'].sum():.2f}
‚Ä¢ Win-back Opportunity (25% success): ${rfm_segments[rfm_segments['segment'] == 'At Risk']['monetary'].sum() * 0.25:.2f}

STRATEGIC RECOMMENDATIONS
------------------------
1. IMMEDIATE (Next 30 days):
   - Launch targeted win-back campaign for At Risk customers
   - Implement VIP program for Champions segment
   - A/B test retention strategies for new customers

2. MEDIUM-TERM (Next 90 days):
   - Develop customer upgrade paths (Regular ‚Üí Loyal ‚Üí Champions)
   - Implement predictive churn model
   - Optimize payment options and checkout experience

3. LONG-TERM (Next 12 months):
   - Build comprehensive customer success program
   - Develop advanced personalization engine
   - Implement multi-touch attribution modeling

PROJECTED ROI IMPACT
-------------------
‚Ä¢ Estimated Revenue Uplift: 15-25%
‚Ä¢ Customer Lifetime Value Improvement: 20-30%
‚Ä¢ Retention Rate Improvement Target: +5-10 percentage points

This analysis provides a comprehensive view of customer behavior patterns and
actionable recommendations for business growth and customer retention improvement.
"""
    
    with open('../outputs/executive_summary.txt', 'w') as f:
        f.write(summary_text)
    
    print("\nüìÑ Executive Summary Generated!")
    print("=" * 60)
    print(summary_text)

if __name__ == "__main__":
    run_comprehensive_analysis()